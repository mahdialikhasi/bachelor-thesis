{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VAE.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMpX9E/3LXbz3KGrRSFeCjK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"dNYjm-Pv0G5R","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419231629,"user_tz":-270,"elapsed":3162,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import tensorflow_addons as tfa\n","from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n","from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import ELU, Embedding, LSTM, Dense, Dropout, Bidirectional, Input, RepeatVector, TimeDistributed, Lambda, Layer\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.initializers import GlorotUniform\n","from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n","from tensorflow.keras import regularizers, losses\n","from tensorflow.keras import backend as K\n","\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","\n","import os\n","import datetime\n","import random\n","\n","tf.compat.v1.disable_eager_execution()"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"DPT_eMwe0Sj9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1597419264495,"user_tz":-270,"elapsed":36013,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"8d1a8bde-75a4-4b0f-fd74-fbf6b540de8a"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HvVyFdS80b-e","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419270670,"user_tz":-270,"elapsed":42184,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["# import dataset from txt file\n","\n","X = np.array(())\n","\n","DataSetPath = '/content/gdrive/My Drive/bsc/Final/DataSet/ferdousi_norm.txt'\n","\n","dataset = pd.read_csv(DataSetPath, na_values=\" \", header=None)\n","temp = dataset.iloc[:, 0].values\n","\n","X = np.append(X, temp)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"2GymW12R1bNe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1597419270671,"user_tz":-270,"elapsed":42176,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"1b4eb25a-2dd7-459e-a72f-10b0f82c3509"},"source":["print(X[:3])\n","print(X[-1])\n","print(X[-2])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["['به نام خداوند جان و خرد' 'کزین برتر اندیشه برنگذرد'\n"," 'خداوند نام و خداوند جای']\n","هر آنکس که دارد هش و رای و دین\n","که تخم سخن من پراگنده ام\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h8ILYNRVFwbi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597419270673,"user_tz":-270,"elapsed":9598,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"2bc1d567-bfcc-4e66-b9a3-e497de7ac7e5"},"source":["print(\"The total count of masraas is \" , len(X))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["The total count of masraas is  99217\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TPp4WmM3FynI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419270675,"user_tz":-270,"elapsed":8112,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["# Train on just a quarter of data\n","X = X[: int(len(X) / 4) ]\n","\n","if len(X) % 2 == 1:\n","    X = X[:-1]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Outk0PV8Fypj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597419270677,"user_tz":-270,"elapsed":6887,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"635ada65-ce46-44f8-9ffb-4053d5b2d99b"},"source":["print(\"The total count of masraas is \" , len(X))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["The total count of masraas is  24804\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ovJpo1nfFyt1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419270678,"user_tz":-270,"elapsed":4900,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["verses = []\n","input_verses = []\n","\n","for i in range(len(X)):\n","    if i % 2 == 0:\n","        input_verses.append(X[i] + ' <middle> ' + X[i + 1] + ' <eos>')\n","        verses.append(X[i] + ' <middle> ' + X[i + 1] + ' <eos>')"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-NMzEcoFylk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597419270679,"user_tz":-270,"elapsed":3382,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"452106a0-1564-4391-d527-3e88f549c6fc"},"source":["print(\"The total number of verses is \", len(verses))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["The total number of verses is  12402\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6sXGZtUwFyjB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419272238,"user_tz":-270,"elapsed":2895,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["# tokenize all data\n","\n","tokenizer = Tokenizer(filters=\"\")\n","tokenizer.fit_on_texts(verses)\n","\n","TokenizedVerses = tokenizer.texts_to_sequences(verses)\n","tokenized_input = tokenizer.texts_to_sequences(input_verses)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"kAtqcrz5F9GX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419272732,"user_tz":-270,"elapsed":2095,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["word2index = tokenizer.word_index\n","index2word = tokenizer.index_word"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3Gnhw5eF9C-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":179},"executionInfo":{"status":"ok","timestamp":1597419273208,"user_tz":-270,"elapsed":1311,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"c6962a29-c126-4813-dd63-4e65f456e87b"},"source":["# find max length for padding\n","\n","max_len = 0\n","\n","for i in tokenized_input:\n","    if len(i) > max_len:\n","        sen = []\n","        for t in i :\n","            sen.append(index2word[t])\n","        print(sen)\n","    max_len = max(max_len, len(i)) \n","\n","print(\"maximum length of sentences : \", max_len)\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["['به', 'نام', 'خداوند', 'جان', 'و', 'خرد', '<middle>', 'کزین', 'برتر', 'اندیشه', 'برنگذرد', '<eos>']\n","['خداوند', 'کیوان', 'و', 'گردان', 'سپهر', '<middle>', 'فروزنده', 'ماه', 'و', 'ناهید', 'و', 'مهر', '<eos>']\n","['نیابد', 'بدو', 'نیز', 'اندیشه', 'راه', '<middle>', 'که', 'او', 'برتر', 'از', 'نام', 'و', 'از', 'جایگاه', '<eos>']\n","['خرد', 'را', 'و', 'جان', 'را', 'همی', 'سنجد', 'اوی', '<middle>', 'در', 'اندیشه', 'سخته', 'کی', 'گنجد', 'اوی', '<eos>']\n","['سه', 'پاس', 'تو', 'چشم', 'است', 'وگوش', 'و', 'زبان', '<middle>', 'کزین', 'سه', 'رسد', 'نیک', 'و', 'بد', 'بی', 'گمان', '<eos>']\n","['نه', 'کند', 'آوری', 'گیرد', 'از', 'باج', 'و', 'گنج', '<middle>', 'نه', 'دل', 'تیره', 'دارد', 'ز', 'رزم', 'و', 'ز', 'رنج', '<eos>']\n","['ز', 'گنج', 'و', 'ز', 'تخت', 'و', 'ز', 'در', 'و', 'گهر', '<middle>', 'ز', 'اسپ', 'و', 'سلیح', 'و', 'کلاه', 'و', 'کمر', '<eos>']\n","['به', 'دیبا', 'و', 'دینار', 'و', 'در', 'و', 'درم', '<middle>', 'به', 'بوی', 'و', 'به', 'رنگ', 'و', 'به', 'هر', 'بیش', 'و', 'کم', '<eos>']\n","maximum length of sentences :  21\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6BoosoYNF8_j","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419275450,"user_tz":-270,"elapsed":1058,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["# do padding\n","\n","input_seq = pad_sequences(tokenized_input, maxlen=max_len, padding='post')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"adc33O6LF88n","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419277271,"user_tz":-270,"elapsed":1103,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["# building model\n","class VAE(object):\n","    def build_model(self, vocab_size, timesteps, intermediate_dim, latent_dim, kl_weight_start = 0, epsilon_std=1.):\n","\n","        \"\"\"\n","        Creates an LSTM Variational Autoencoder (VAE). Returns VAE, Encoder, Generator. \n","        # Arguments\n","            timesteps: int, input timestep dimension. e.g sentences max size\n","            intermediate_dim: int, output shape of LSTM. \n","            latent_dim: int, latent z-layer shape. \n","            epsilon_std: float, z-layer sigma.\n","        # References\n","            - [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)\n","            - [Generating sentences from a continuous space](https://arxiv.org/abs/1511.06349)\n","        \"\"\"\n","        \n","        self.vae = None\n","        self.encoder = None\n","        self.generator = None\n","        self.kl_weight_start = kl_weight_start\n","        self.kl_weight = None\n","\n","        x = Input(shape=(timesteps,))\n","        embed = Embedding(vocab_size, 256, input_length=timesteps)(x)\n","\n","        # LSTM encoding\n","        h = Bidirectional(LSTM(intermediate_dim, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001), return_sequences=True), merge_mode=\"concat\")(embed)\n","        h = Bidirectional(LSTM(intermediate_dim, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)), merge_mode=\"concat\")(h)\n","        h = Dense(intermediate_dim, activation='linear')(h)\n","        h = ELU()(h)\n","\n","        # VAE Z layer\n","        z_mean = Dense(latent_dim)(h)\n","        z_log_sigma = Dense(latent_dim)(h)\n","        \n","        def sampling(args):\n","            z_mean_, z_log_var_ = args\n","            \n","            epsilon = K.random_normal(shape=tf.shape(z_mean_), mean=0., stddev=epsilon_std)\n","            return z_mean_ + K.exp(z_log_var_ / 2) * epsilon\n","\n","        z = Lambda(sampling)([z_mean, z_log_sigma])\n","        \n","        # decoded LSTM layer\n","        repeated_context = RepeatVector(timesteps)\n","        decoder_h = LSTM(intermediate_dim, return_sequences=True, kernel_regularizer=regularizers.l2(0.001))\n","        decoder_mean = TimeDistributed(Dense(vocab_size, activation='linear')) \n","\n","        h_decoded = decoder_h(repeated_context(z))\n","        x_decoded_mean = decoder_mean(h_decoded)\n","\n","        def vae_loss():\n","            self.kl_weight = K.variable(self.kl_weight_start, name='kl_weight')\n","            kl_weight = self.kl_weight\n","            \n","            def loss(y_true, y_pred):  \n","                labels = tf.cast(x, tf.int32)\n","\n","                xent_loss = K.sum(tfa.seq2seq.sequence_loss(x_decoded_mean, labels, \n","                                                                weights=tf.ones(tf.shape(x), tf.float32),\n","                                                                average_across_timesteps=False,\n","                                                                average_across_batch=False), axis=-1)\n","                                                                #softmax_loss_function=softmax_loss_f), axis=-1)#, uncomment for sampled doftmax\n","                kl_loss = - 0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n","                kl_loss = kl_loss * kl_weight\n","\n","                return K.mean(xent_loss + kl_loss)\n","            return loss\n","            \n","\n","        # end-to-end autoencoder\n","        self.vae = Model(x, x_decoded_mean)\n","\n","        # encoder, from inputs to latent space\n","        self.encoder = Model(x, z)\n","\n","        # generator, from latent space to reconstructed inputs\n","        decoder_input = Input(shape=(latent_dim))\n","\n","        _h_decoded = decoder_h(repeated_context(decoder_input))\n","\n","        _x_decoded_mean = decoder_mean(_h_decoded)\n","        self.generator = Model(decoder_input, _x_decoded_mean)\n","        \n","        opt = Adam(lr=0.01) #SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n","        \n","        self.vae.compile(optimizer='adam', loss=vae_loss())\n","        # vae.summary()\n","\n","        # return vae, encoder, generator\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3ATFhWpLC80","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1597419284320,"user_tz":-270,"elapsed":3691,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"6dfe0cdb-2fd7-4371-96e5-2353cf6d3e09"},"source":["base_path = \"/content/gdrive/My Drive/bsc/Final/VAE/\"\n","!ls \"/content/gdrive/My Drive/bsc/Final/VAE/\""],"execution_count":15,"outputs":[{"output_type":"stream","text":["checkpoint\t\t     imputing_batch.txt\n","cp.ckpt.data-00000-of-00002  reconstruct_sentences_during_training.txt\n","cp.ckpt.data-00001-of-00002  sample_sentences_during_training.txt\n","cp.ckpt.index\t\t     verses_batch.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G8B7b2AALKlC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419285642,"user_tz":-270,"elapsed":764,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["# sample from model\n","\n","def sample_line(model, latent_dim, type = 1):\n","    middle = word2index['<middle>']\n","    eos = word2index['<eos>']\n","\n","    mu, stddev = 0, 1 \n","    z = np.random.default_rng().normal(mu, stddev, size = (1, latent_dim))\n","    \n","    seq = model.predict(z)\n","\n","    output_sentence = []\n","\n","    for i in range(max_len):\n","        probs = np.exp(seq[0][i])\n","        probs[0] = 0\n","\n","        idx = 0\n","        if type == 0:\n","            probs /= probs.sum()\n","            idx = np.random.choice(len(probs), p=probs)\n","        elif type == 1:\n","            idx = np.argmax(probs)\n","        \n","        if idx == eos:\n","            break\n","        if idx == 0:\n","            continue\n","        if idx == middle:\n","            output_sentence.append(\"    -   \")\n","        else:\n","            output_sentence.append(index2word[idx])\n","\n","    decoded_review = ' '.join(output_sentence)\n","\n","    return decoded_review"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"QJyOKKj5Log5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419287752,"user_tz":-270,"elapsed":1132,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["# reconstruct\n","\n","def reconstruct_line(model, latent_dim):\n","    middle = word2index['<middle>']\n","    eos = word2index['<eos>']\n","\n","    num = random.randrange(len(input_seq) - 1)\n","    input_sentence = input_seq[num:num + 1]\n","    output_sentence = model.predict(input_sentence)\n","\n","    output_sentence_text = []\n","    input_sentence_text = []\n","\n","    for i in input_sentence[0]:\n","        if i != 0:\n","            input_sentence_text.append(index2word[i])\n","\n","    for i in range(max_len):\n","        probs = output_sentence[0][i]\n","        probs[0] = 0\n","\n","        idx = 0\n","        idx = np.argmax(probs)\n","\n","        if idx == eos:\n","            output_sentence_text.append(index2word[idx])\n","            break\n","        if idx == 0:\n","            continue\n","        else:\n","            output_sentence_text.append(index2word[idx])\n","\n","    decoded_review1 = ' '.join(input_sentence_text)\n","    decoded_review2 = ' '.join(output_sentence_text)\n","\n","    return decoded_review1 + \" ==> \" + decoded_review2"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"agxmDAhaMOnO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419290446,"user_tz":-270,"elapsed":1087,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["# create custom callback\n","class MyCustomCallback(tf.keras.callbacks.Callback):\n","\n","    def __init__(self, generator, latent_dim, initial_epoch = 0):\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","        self.initial_epoch = initial_epoch\n","\n","    \n","    def on_epoch_end(self, epoch, logs=None):\n","        print('Training: epoch {} ends at {}'.format(epoch + self.initial_epoch, datetime.datetime.now().time()))\n","        print('sample text via predict : ')\n","        sentence = sample_line(self.generator, self.latent_dim)\n","        print(sentence)\n","        \n","        _path = base_path + \"sample_sentences_during_training.txt\"\n","        file_object = open(_path, 'a+')\n","        file_object.write('\\n Training: epoch {} ends at {} \\n'.format(epoch + self.initial_epoch, datetime.datetime.now().time()))\n","        file_object.write('sample text via predict : \\n')\n","        file_object.write(sentence)\n","        file_object.close()\n","  "],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"hNEUKnT5MswW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419293113,"user_tz":-270,"elapsed":953,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["# create custom callback\n","kl_annealtime = 30\n","\n","class KLAnnealing(tf.keras.callbacks.Callback):\n","    def __init__(self, kl_weight, initial_epoch = 0):\n","        super(KLAnnealing, self).__init__()\n","        self.kl_weight = kl_weight\n","        self.initial_epoch = initial_epoch\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if epoch + self.initial_epoch > kl_annealtime:\n","            new_kl_weight = K.get_value(self.kl_weight) + 0.01\n","            if new_kl_weight < 1:\n","                K.set_value(self.kl_weight, new_kl_weight)\n","                print('\\nEpoch %05d: KLWeightScheduler setting KL weight '\n","                  ' to %s.' % (epoch + self.initial_epoch, new_kl_weight))\n","  "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPntarYpNHgU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419294545,"user_tz":-270,"elapsed":717,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["# create custom callback\n","class Reconstruct(tf.keras.callbacks.Callback):\n","    \n","    def __init__(self, latent_dim, initial_epoch = 0):\n","        self.latent_dim = latent_dim\n","        self.initial_epoch = initial_epoch\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        print('Training: epoch {} ends at {}'.format(epoch + self.initial_epoch, datetime.datetime.now().time()))\n","        print('reconstruct text via predict : ')\n","        sentence = reconstruct_line(self.model, self.latent_dim)\n","        print(sentence)\n","        \n","        _path = base_path + \"reconstruct_sentences_during_training.txt\"\n","        file_object = open(_path, 'a+')\n","        file_object.write('\\n Training: epoch {} ends at {} \\n'.format(epoch + self.initial_epoch, datetime.datetime.now().time()))\n","        file_object.write('reconstruct text via predict : \\n')\n","        file_object.write(sentence)\n","        file_object.close()\n","  "],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"FXUoiOUJOdIh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419301109,"user_tz":-270,"elapsed":965,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}}},"source":["# create custom callback to save loss\n","\n","class MyCustomCallbackLoss(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):    \n","        loss_path = base_path + \"loss.txt\"\n","        print(\"saving loss\")\n","        file_object = open(loss_path, 'a+')\n","        file_object.write('{}\\n'.format(logs[\"loss\"]))\n","        file_object.close()\n","  "],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXRVo1ZONV4_","colab_type":"code","colab":{}},"source":["# train model\n","\n","LATENT_SIZE = 512\n","EPOCH_TIME = 100\n","WORD_NUM = len(index2word) + 1\n","\n","# Create a callback that saves the model's weights\n","checkpoint_path = base_path + \"cp.ckpt\" \n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True)\n","\n","model = VAE()\n","model.build_model(vocab_size = WORD_NUM, timesteps = max_len, intermediate_dim = 512, latent_dim = LATENT_SIZE)\n","model.vae.fit(input_seq[:1000], input_seq[:1000], batch_size=100, epochs = EPOCH_TIME, validation_split= 0.2,\n","        shuffle=True, verbose=1,\n","        callbacks=[\n","                   cp_callback,\n","                   MyCustomCallback(model.generator, LATENT_SIZE),\n","                   Reconstruct(LATENT_SIZE),\n","                   KLAnnealing(model.kl_weight),\n","                   MyCustomCallbackLoss()\n","                   ]\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"di9i9yZdNn_p","colab_type":"code","colab":{}},"source":["# train base on last checkpoint\n","\n","LATENT_SIZE = 512\n","EPOCH_TIME = 1\n","PR_EPOCHS = 485\n","WORD_NUM = len(index2word) + 1\n","\n","# Create a callback that saves the model's weights\n","checkpoint_path = base_path + \"cp.ckpt\" \n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, save_weights_only=True)\n","\n","model = VAE()\n","\n","model.build_model(vocab_size = WORD_NUM, timesteps = max_len, intermediate_dim = 512, latent_dim = LATENT_SIZE, kl_weight_start = 1)\n","model.vae.load_weights(checkpoint_path)\n","\n","model.vae.fit(input_seq, input_seq, batch_size=100, epochs = EPOCH_TIME, validation_split= 0.2,\n","        shuffle=True, verbose=1,\n","        callbacks=[\n","                   cp_callback,\n","                   MyCustomCallback(model.generator, LATENT_SIZE, initial_epoch=PR_EPOCHS),\n","                   Reconstruct(LATENT_SIZE, initial_epoch=PR_EPOCHS),\n","                   KLAnnealing(model.kl_weight, initial_epoch=PR_EPOCHS),\n","                   MyCustomCallbackLoss()\n","                ]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJAx-nnTN8rs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597419311971,"user_tz":-270,"elapsed":7663,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"fbe43539-5d1f-44aa-cf65-35daa45792fa"},"source":["# load model base on last checkpoint\n","\n","LATENT_SIZE = 512\n","WORD_NUM = len(index2word) + 1\n","\n","# Create a callback that saves the model's weights\n","checkpoint_path = base_path + \"cp.ckpt\" \n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","model = VAE()\n","\n","model.build_model(vocab_size = WORD_NUM, timesteps = max_len, intermediate_dim = 512, latent_dim = LATENT_SIZE, kl_weight_start = 1)\n","model.vae.load_weights(checkpoint_path)"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc3be6c0710>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"2AUtvtdJOCJu","colab_type":"code","colab":{}},"source":["# sample from model\n","\n","for i in range(30):\n","    print(sample_line(model.generator, LATENT_SIZE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqveqWA2OLf0","colab_type":"code","colab":{}},"source":["# plot loss\n","loss = pd.read_csv(base_path + \"loss.txt\", header=None)\n","loss = loss.iloc[:,0].values\n","\n","plt.plot(loss)\n","plt.ylabel(\"Loss function\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OsMg10biPHod","colab_type":"code","colab":{}},"source":["# showing model graph\n","from tensorflow.keras.utils import plot_model\n","plot_model(model.vae, to_file= base_path + 'model_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jyito0XPNCL","colab_type":"code","colab":{}},"source":["# text imputing\n","index = np.random.randint(0, int(len(X) / 4)) \n","if index % 2 == 1:\n","    index -= 1\n","verse_text = []\n","verse_text.append(X[index] + \" <middle> \" + X[index + 1] + \" <eos>\")\n","# print(verse_text)\n","verse_text = tokenizer.texts_to_sequences(verse_text)\n","verse_text_seq = pad_sequences(verse_text, maxlen=max_len, padding='post')\n","# print(verse_text_seq)\n","\n","def print_sent_from_seq(seq):\n","    output_sen = []\n","    for i in seq:\n","        if i == word2index[\"<eos>\"]:\n","            break\n","        if i == 0:\n","            continue\n","        if i == word2index[\"<middle>\"]:\n","            output_sen.append(\"    -   \")\n","        elif i == -1:\n","            output_sen.append(\"?\")\n","        else:\n","            output_sen.append(index2word[i])\n","\n","    decoded_review = ' '.join(output_sen)\n","    print(decoded_review)\n","\n","# remove k word at random\n","\n","k = 2\n","index_array = []\n","\n","print(\"real sentence : \")\n","print_sent_from_seq(verse_text_seq[0])\n","\n","for i in range(k):\n","    index = np.random.randint(0, max_len)\n","    while verse_text_seq[0][index] == word2index[\"<middle>\"] or verse_text_seq[0][index] == word2index[\"<eos>\"] or verse_text_seq[0][index] == 0:\n","         index = np.random.randint(0, max_len)\n","    index_array.append(index)\n","    verse_text_seq[0][index] = 0\n","\n","print(\"After removing some words : \")\n","verse_text_seq_temp = verse_text_seq[0].copy()\n","for i in index_array:\n","    verse_text_seq_temp[i] = -1\n","print_sent_from_seq(verse_text_seq_temp)\n","\n","z_hat = model.encoder.predict(verse_text_seq)\n","y_hat = model.generator.predict(z_hat)\n","\n","for i in index_array:\n","    probs = np.exp(y_hat[0][i])\n","    probs[0] = 0\n","\n","    idx = 0\n","    idx = np.argmax(probs)\n","\n","    verse_text_seq[0][i] = idx\n","\n","print(\"After text imputing : \")\n","print_sent_from_seq(verse_text_seq[0])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CNCNghdWnIYb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1597419571414,"user_tz":-270,"elapsed":1072,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"f4175768-ba1f-4cf5-8cd6-4cc1b742198d"},"source":["# text imputing on test set\n","index = np.random.randint(int(len(X) / 4), len(X))\n","if index % 2 == 1:\n","    index -= 1\n","verse_text = []\n","verse_text.append(X[index] + \" <middle> \" + X[index + 1] + \" <eos>\")\n","# print(verse_text)\n","verse_text = tokenizer.texts_to_sequences(verse_text)\n","verse_text_seq = pad_sequences(verse_text, maxlen=max_len, padding='post')\n","# print(verse_text_seq)\n","\n","def print_sent_from_seq(seq):\n","    output_sen = []\n","    for i in seq:\n","        if i == word2index[\"<eos>\"]:\n","            break\n","        if i == 0:\n","            continue\n","        if i == word2index[\"<middle>\"]:\n","            output_sen.append(\"    -   \")\n","        elif i == -1:\n","            output_sen.append(\"?\")\n","        else:\n","            output_sen.append(index2word[i])\n","\n","    decoded_review = ' '.join(output_sen)\n","    print(decoded_review)\n","\n","# remove k word at random\n","\n","k = 2\n","index_array = []\n","\n","print(\"real sentence : \")\n","print_sent_from_seq(verse_text_seq[0])\n","\n","for i in range(k):\n","    index = np.random.randint(0, max_len)\n","    while verse_text_seq[0][index] == word2index[\"<middle>\"] or verse_text_seq[0][index] == word2index[\"<eos>\"] or verse_text_seq[0][index] == 0:\n","         index = np.random.randint(0, max_len)\n","    index_array.append(index)\n","    verse_text_seq[0][index] = 0\n","\n","print(\"After removing some words : \")\n","verse_text_seq_temp = verse_text_seq[0].copy()\n","for i in index_array:\n","    verse_text_seq_temp[i] = -1\n","print_sent_from_seq(verse_text_seq_temp)\n","\n","z_hat = model.encoder.predict(verse_text_seq)\n","y_hat = model.generator.predict(z_hat)\n","\n","for i in index_array:\n","    probs = np.exp(y_hat[0][i])\n","    probs[0] = 0\n","\n","    idx = 0\n","    idx = np.argmax(probs)\n","\n","    verse_text_seq[0][i] = idx\n","\n","print(\"After text imputing : \")\n","print_sent_from_seq(verse_text_seq[0])\n","\n"],"execution_count":31,"outputs":[{"output_type":"stream","text":["real sentence : \n","ز بهر بزرگان ایران زمین     -    برآرامش این رنج کردی گزین\n","After removing some words : \n","ز ? ? ایران زمین     -    برآرامش این رنج کردی گزین\n","After text imputing : \n","ز چندان بزرگان ایران زمین     -    برآرامش این رنج کردی گزین\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W1VEGjdEoKHw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1597420422991,"user_tz":-270,"elapsed":36938,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"f2129dc7-4f32-494f-e654-15e47ff944c9"},"source":["# computing text imputing accuracy\n","error = 0\n","acc = 0\n","for p in range(500):\n","    index = np.random.randint(0, int(len(X) / 4)) \n","    if index % 2 == 1:\n","        index -= 1\n","    verse_text = []\n","    verse_text.append(X[index] + \" <middle> \" + X[index + 1] + \" <eos>\")\n","\n","    verse_text = tokenizer.texts_to_sequences(verse_text)\n","    verse_text_seq = pad_sequences(verse_text, maxlen=max_len, padding='post')\n","    \n","    # remove k word at random\n","    k = 2\n","    index_array = []\n","    value_array = []\n","\n","    for i in range(k):\n","        index = np.random.randint(0, max_len)\n","        while verse_text_seq[0][index] == word2index[\"<middle>\"] or verse_text_seq[0][index] == word2index[\"<eos>\"] or verse_text_seq[0][index] == 0:\n","            index = np.random.randint(0, max_len)\n","        index_array.append(index)\n","        value_array.append(verse_text_seq[0][index])\n","        verse_text_seq[0][index] = 0\n","\n","    z_hat = model.encoder.predict(verse_text_seq)\n","    y_hat = model.generator.predict(z_hat)\n","\n","    for k in range(len(index_array)):\n","        i = index_array[k]\n","\n","        probs = np.exp(y_hat[0][i])\n","        probs[0] = 0\n","        probs /= sum(probs)\n","\n","        idx = 0\n","        idx = np.argmax(probs)\n","        error += -np.log(probs[value_array[k]])\n","        acc += probs[value_array[k]]\n","\n","        verse_text_seq[0][i] = idx\n","\n","print(acc / 500)\n","print(error / 500)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["0.538278013484222\n","8.064722566499796\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r9PKLeTImU48","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595050658690,"user_tz":-270,"elapsed":87457,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"c339cf35-e158-464b-d697-ce72873d3b57"},"source":["# create new batch verses\n","\n","def sample_line_with_token(model, latent_dim):\n","    middle = word2index['<middle>']\n","    eos = word2index['<eos>']\n","\n","    mu, stddev = 0, 1 \n","    z = np.random.default_rng().normal(mu, stddev, size = (1, latent_dim))\n","    \n","    seq = model.predict(z)\n","\n","    output_sentence = []\n","\n","    for i in range(max_len):\n","        probs = np.exp(seq[0][i])\n","        probs[0] = 0\n","\n","        idx = 0\n","        \n","        idx = np.argmax(probs)\n","        \n","        if idx == eos:\n","            break\n","        if idx == 0:\n","            continue\n","        else:\n","            output_sentence.append(index2word[idx])\n","\n","    decoded_review = ' '.join(output_sentence)\n","\n","    return decoded_review\n","\n","\n","verses_batch_path = base_path + \"verses_batch.txt\"\n","print(\"saving verses batch\")\n","file_object = open(verses_batch_path, 'a+')\n","\n","for i in range(4000):\n","    verse = sample_line_with_token(model.generator, LATENT_SIZE)\n","    file_object.write('{}\\n'.format(verse))\n","\n","file_object.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["saving verses batch\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"05mvJ7O72bkt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595051284150,"user_tz":-270,"elapsed":247703,"user":{"displayName":"Mahdi Alikhasi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9sJL4cfPFdci7OCuLZK7J9N4BTZUmK3KwXSyyNQ=s64","userId":"14343546345204256949"}},"outputId":"3a7098bf-4ec1-472c-d865-c4de26f71b09"},"source":["# create new batch imputing\n","\n","imputing_batch_path = base_path + \"imputing_batch.txt\"\n","print(\"saving imputing batch\")\n","file_object = open(imputing_batch_path, 'a+')\n","\n","for j in range(4000):\n","    index = np.random.randint(0, int(len(X) / 4)) \n","    \n","    if index % 2 == 1:\n","        index -= 1\n","    \n","    verse_text = []\n","    verse_text.append(X[index] + \" <middle> \" + X[index + 1] + \" <eos>\")\n","\n","    verse_text = tokenizer.texts_to_sequences(verse_text)\n","    verse_text_seq = pad_sequences(verse_text, maxlen=max_len, padding='post')\n","\n","    k = 3\n","    index_array = []\n","\n","    for i in range(k):\n","        index = np.random.randint(0, max_len)\n","        while verse_text_seq[0][index] == word2index[\"<middle>\"] or verse_text_seq[0][index] == word2index[\"<eos>\"] or verse_text_seq[0][index] == 0:\n","            index = np.random.randint(0, max_len)\n","        index_array.append(index)\n","        verse_text_seq[0][index] = 0\n","\n","    z_hat = model.encoder.predict(verse_text_seq)\n","    y_hat = model.generator.predict(z_hat)\n","\n","    for i in index_array:\n","        probs = np.exp(y_hat[0][i])\n","        probs[0] = 0\n","\n","        idx = 0\n","        idx = np.argmax(probs)\n","\n","        verse_text_seq[0][i] = idx\n","\n","    output_sentence = []\n","    for i in range(max_len):\n","        if verse_text_seq[0][i] == word2index[\"<eos>\"]:\n","            break\n","        if verse_text_seq[0][i] == 0:\n","            continue\n","        else:\n","            output_sentence.append(index2word[verse_text_seq[0][i]])\n","        \n","    decoded_review = ' '.join(output_sentence)\n","\n","    file_object.write('{}\\n'.format(decoded_review))\n","\n","file_object.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["saving imputing batch\n"],"name":"stdout"}]}]}